{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbfb5f7b",
   "metadata": {},
   "source": [
    "## Simulation 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02291250",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b9dc8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74dda14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gymnasium as gym\n",
    "import tqdm\n",
    "import rich\n",
    "from gymnasium import spaces\n",
    "from pathlib import Path\n",
    "from floris import FlorisModel\n",
    "from floris.flow_visualization import visualize_cut_plane\n",
    "from stable_baselines3 import PPO, DDPG\n",
    "from stable_baselines3.common.noise import NormalActionNoise\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea54299",
   "metadata": {},
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ff81307",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/floris312/lib/python3.12/site-packages/gymnasium/spaces/box.py:236: UserWarning: \u001b[33mWARN: Box low's precision lowered by casting to float32, current low.dtype=float64\u001b[0m\n",
      "  gym.logger.warn(\n",
      "/opt/anaconda3/envs/floris312/lib/python3.12/site-packages/gymnasium/spaces/box.py:306: UserWarning: \u001b[33mWARN: Box high's precision lowered by casting to float32, current high.dtype=float64\u001b[0m\n",
      "  gym.logger.warn(\n"
     ]
    }
   ],
   "source": [
    "class FlorisEnv(gym.Env):\n",
    "    def __init__(self, config_path):\n",
    "        super(FlorisEnv, self).__init__()\n",
    "        self.fmodel = FlorisModel(config_path)\n",
    "        \n",
    "        # Setup Farm Layout\n",
    "        D = 126.0\n",
    "        self.x_layout = [0, 0, 6 * D, 6 * D]\n",
    "        self.y_layout = [0, 3 * D, 0, 3 * D]\n",
    "        self.fmodel.set(layout_x=self.x_layout, layout_y=self.y_layout)\n",
    "        self.n_turbines = len(self.x_layout)\n",
    "        \n",
    "        self.action_space = spaces.Box(low=-1.0, high=1.0, shape=(self.n_turbines,), dtype=np.float32)\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=np.array([270.0, 8.0, 0.05]), \n",
    "            high=np.array([280.0, 11.0, 0.20]), \n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.current_wd = np.random.uniform(270.0, 280.0)\n",
    "        self.current_ws = np.random.uniform(8.0, 11.0)\n",
    "        self.current_ti = np.random.uniform(0.05, 0.20)\n",
    "        return np.array([self.current_wd, self.current_ws, self.current_ti], dtype=np.float32), {}\n",
    "\n",
    "    def step(self, action):\n",
    "        yaw_angles = action * 25.0\n",
    "        \n",
    "        # Baseline\n",
    "        self.fmodel.set(wind_directions=[self.current_wd], wind_speeds=[self.current_ws], \n",
    "                        turbulence_intensities=[self.current_ti], yaw_angles=np.zeros((1, self.n_turbines)))\n",
    "        self.fmodel.run()\n",
    "        baseline_mw = np.sum(self.fmodel.get_turbine_powers()) / 1e6\n",
    "\n",
    "        # Control\n",
    "        self.fmodel.set(yaw_angles=np.array([yaw_angles]))\n",
    "        self.fmodel.run()\n",
    "        rl_mw = np.sum(self.fmodel.get_turbine_powers()) / 1e6\n",
    "        \n",
    "        gain_pct = 100 * (rl_mw - baseline_mw) / baseline_mw\n",
    "        obs = np.array([self.current_wd, self.current_ws, self.current_ti], dtype=np.float32)\n",
    "        \n",
    "        return obs, rl_mw, True, False, {\"baseline_kw\": baseline_mw * 1000, \"power_kw\": rl_mw * 1000, \"gain_pct\": gain_pct}\n",
    "\n",
    "# Initialize Env (Update this path to your actual yaml file)\n",
    "CONFIG_PATH = \"data_generation/farm_types/gch.yaml\" \n",
    "env = FlorisEnv(CONFIG_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aad8b2e",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "89f90cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training PPO...\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "You must install tqdm and rich in order to use the progress bar callback. It is included if you install stable-baselines with the extra packages: `pip install stable-baselines3[extra]`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     10\u001b[39m     model.learn(\n\u001b[32m     11\u001b[39m         total_timesteps=steps, \n\u001b[32m     12\u001b[39m         tb_log_name=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00malgo\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_run\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     13\u001b[39m         progress_bar=\u001b[38;5;28;01mTrue\u001b[39;00m \n\u001b[32m     14\u001b[39m     )\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m ppo_model = \u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPPO\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m20000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m ddpg_model = run_training(\u001b[33m\"\u001b[39m\u001b[33mDDPG\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m20000\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mrun_training\u001b[39m\u001b[34m(algo, steps)\u001b[39m\n\u001b[32m      7\u001b[39m     model = DDPG(\u001b[33m\"\u001b[39m\u001b[33mMlpPolicy\u001b[39m\u001b[33m\"\u001b[39m, env, action_noise=noise, verbose=\u001b[32m0\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining \u001b[39m\u001b[38;5;132;01m{\u001b[39;00malgo\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m=\u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43malgo\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m_run\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/floris312/lib/python3.12/site-packages/stable_baselines3/ppo/ppo.py:311\u001b[39m, in \u001b[36mPPO.learn\u001b[39m\u001b[34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[39m\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlearn\u001b[39m(\n\u001b[32m    303\u001b[39m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[32m    304\u001b[39m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    309\u001b[39m     progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    310\u001b[39m ) -> SelfPPO:\n\u001b[32m--> \u001b[39m\u001b[32m311\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/floris312/lib/python3.12/site-packages/stable_baselines3/common/on_policy_algorithm.py:311\u001b[39m, in \u001b[36mOnPolicyAlgorithm.learn\u001b[39m\u001b[34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[39m\n\u001b[32m    300\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlearn\u001b[39m(\n\u001b[32m    301\u001b[39m     \u001b[38;5;28mself\u001b[39m: SelfOnPolicyAlgorithm,\n\u001b[32m    302\u001b[39m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    307\u001b[39m     progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    308\u001b[39m ) -> SelfOnPolicyAlgorithm:\n\u001b[32m    309\u001b[39m     iteration = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m311\u001b[39m     total_timesteps, callback = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_setup_learn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    319\u001b[39m     callback.on_training_start(\u001b[38;5;28mlocals\u001b[39m(), \u001b[38;5;28mglobals\u001b[39m())\n\u001b[32m    321\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.env \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/floris312/lib/python3.12/site-packages/stable_baselines3/common/base_class.py:434\u001b[39m, in \u001b[36mBaseAlgorithm._setup_learn\u001b[39m\u001b[34m(self, total_timesteps, callback, reset_num_timesteps, tb_log_name, progress_bar)\u001b[39m\n\u001b[32m    431\u001b[39m     \u001b[38;5;28mself\u001b[39m._logger = utils.configure_logger(\u001b[38;5;28mself\u001b[39m.verbose, \u001b[38;5;28mself\u001b[39m.tensorboard_log, tb_log_name, reset_num_timesteps)\n\u001b[32m    433\u001b[39m \u001b[38;5;66;03m# Create eval callback if needed\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m434\u001b[39m callback = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_init_callback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m total_timesteps, callback\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/floris312/lib/python3.12/site-packages/stable_baselines3/common/base_class.py:378\u001b[39m, in \u001b[36mBaseAlgorithm._init_callback\u001b[39m\u001b[34m(self, callback, progress_bar)\u001b[39m\n\u001b[32m    376\u001b[39m \u001b[38;5;66;03m# Add progress bar callback\u001b[39;00m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m progress_bar:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     callback = CallbackList([callback, \u001b[43mProgressBarCallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m])\n\u001b[32m    380\u001b[39m callback.init_callback(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    381\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m callback\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/floris312/lib/python3.12/site-packages/stable_baselines3/common/callbacks.py:709\u001b[39m, in \u001b[36mProgressBarCallback.__init__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    707\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n\u001b[32m    708\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tqdm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m709\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m    710\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou must install tqdm and rich in order to use the progress bar callback. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    711\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIt is included if you install stable-baselines with the extra packages: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    712\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`pip install stable-baselines3[extra]`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    713\u001b[39m     )\n",
      "\u001b[31mImportError\u001b[39m: You must install tqdm and rich in order to use the progress bar callback. It is included if you install stable-baselines with the extra packages: `pip install stable-baselines3[extra]`"
     ]
    }
   ],
   "source": [
    "def run_training(algo=\"PPO\", steps=10000):\n",
    "    if algo == \"PPO\":\n",
    "        model = PPO(\"MlpPolicy\", env, verbose=0)\n",
    "    else:\n",
    "        n_actions = env.action_space.shape[-1]\n",
    "        noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
    "        model = DDPG(\"MlpPolicy\", env, action_noise=noise, verbose=0)\n",
    "    \n",
    "    print(f\"Training {algo}...\")\n",
    "    model.learn(\n",
    "        total_timesteps=steps, \n",
    "        tb_log_name=f\"{algo}_run\",\n",
    "        progress_bar=True \n",
    "    )\n",
    "    return model\n",
    "\n",
    "ppo_model = run_training(\"PPO\", 20000)\n",
    "ddpg_model = run_training(\"DDPG\", 20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9e9da2",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93490c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_agents(models, n_episodes=30):\n",
    "    results = []\n",
    "    for i in range(n_episodes):\n",
    "        obs, _ = env.reset()\n",
    "        # Baseline check\n",
    "        _, _, _, _, info_base = env.step(np.zeros(env.n_turbines))\n",
    "        \n",
    "        data = {\"Episode\": i, \"Baseline\": info_base['power_kw']}\n",
    "        for name, model in models.items():\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "            _, _, _, _, info = env.step(action)\n",
    "            data[name] = info['power_kw']\n",
    "            data[f\"{name}_Gain%\"] = info['gain_pct']\n",
    "        results.append(data)\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "df_results = compare_agents({\"PPO\": ppo_model, \"DDPG\": ddpg_model})\n",
    "\n",
    "\n",
    "# 1. Setup a specific test case\n",
    "obs, _ = env.reset()\n",
    "# Let's say we want to visualize the PPO agent's decision\n",
    "action, _ = ppo_model.predict(obs, deterministic=True)\n",
    "yaw_angles = action * 25.0\n",
    "\n",
    "# 2. Update FLORIS model with the chosen yaw\n",
    "env.fmodel.set(yaw_angles=np.array([yaw_angles]))\n",
    "env.fmodel.run()\n",
    "\n",
    "# 3. Calculate a horizontal plane at hub height\n",
    "# height=90.0 is typical, or use env.fmodel.core.farm.hub_heights[0]\n",
    "hor_plane = env.fmodel.calculate_horizontal_plane(\n",
    "    x_resolution=200, \n",
    "    y_resolution=100, \n",
    "    height=90.0 \n",
    ")\n",
    "\n",
    "# 4. Plot the flow field\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "visualize_cut_plane(hor_plane, ax=ax, title=\"Wake Steering Flow Field (PPO Agent)\")\n",
    "\n",
    "# Add turbine markers to the plot\n",
    "for x, y in zip(env.x_layout, env.y_layout):\n",
    "    ax.plot(x, y, \"ko\", markersize=5) \n",
    "\n",
    "plt.show()\n",
    "\n",
    "def plot_behavior_analysis(df_results):\n",
    "    # We want to see how Yaw Action correlates with Wind Direction\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plotting how the first turbine (the main wake maker) yaws relative to wind direction\n",
    "    sns.scatterplot(data=df_results, x='Wind_Direction', y='Turbine_0_Yaw', hue='PPO_Gain%')\n",
    "    plt.title(\"Agent Strategy: Turbine 0 Yaw vs. Wind Direction\")\n",
    "    plt.axhline(0, color='black', linestyle='--')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "# (Ensure your evaluation loop saves 'Wind_Direction' and 'Turbine_0_Yaw' into the results DF)\n",
    "\n",
    "def compare_wake_plots(env, models, test_obs):\n",
    "    fig, axes = plt.subplots(len(models), 1, figsize=(12, 5 * len(models)))\n",
    "    \n",
    "    # Standard wind condition for comparison\n",
    "    wd, ws, ti = test_obs\n",
    "    \n",
    "    for i, (name, model) in enumerate(models.items()):\n",
    "        action, _ = model.predict(test_obs, deterministic=True)\n",
    "        yaw_angles = action * 25.0\n",
    "        \n",
    "        env.fmodel.set(wind_directions=[wd], wind_speeds=[ws], \n",
    "                        turbulence_intensities=[ti], yaw_angles=np.array([yaw_angles]))\n",
    "        env.fmodel.run()\n",
    "        \n",
    "        hor_plane = env.fmodel.calculate_horizontal_plane(height=90.0)\n",
    "        visualize_cut_plane(hor_plane, ax=axes[i], title=f\"{name} Strategy (Yaw: {np.round(yaw_angles, 1)})\")\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Usage:\n",
    "# test_obs, _ = env.reset()\n",
    "# compare_wake_plots(env, {\"PPO\": ppo_model, \"DDPG\": ddpg_model}, test_obs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "floris312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
